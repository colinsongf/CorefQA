# Main configuration. Do not edit! Copy to experiments.conf and change that.
data_dir = data
best {
  # Edit this
  model_type = independent
  # Computation limits.
  max_top_antecedents = 50
  max_training_sentences = 5
  top_span_ratio = 0.4
  max_num_speakers = 20
  max_segment_len = 256

  # Learning
  bert_learning_rate = 1e-5
  task_learning_rate = 2e-4
  num_docs = 2802

  # Model hyperparameters.
  dropout_rate = 0.3
  ffnn_size = 1000
  ffnn_depth = 1
  num_epochs = 20
  feature_size = 20
  max_span_width = 30
  use_metadata = true
  use_features = true
  use_segment_distance = true
  model_heads = true
  coref_depth = 2
  coarse_to_fine = true
  fine_grained = true
  use_prior = true

  # Other.
  train_path = train.english.jsonlines
  eval_path = test.english.jsonlines
  conll_eval_path = test.english.v4_gold_conll
  single_example = true
  genres = ["bc", "bn", "mz", "nw", "pt", "tc", "wb"]
  eval_frequency = 1000
  report_frequency = 100
  log_root = ${data_dir}
  adam_eps = 1e-6
  task_optimizer = adam
}

bert_base = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 128
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/test.english.128.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
}

train_spanbert_base_128 = ${best}{
  num_docs = 2802
  bert_learning_rate = 2e-05
  task_learning_rate = 0.0001
  max_segment_len = 128
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/test.english.128.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}

train_spanbert_base_fast = ${best}{
  num_docs = 2802
  bert_learning_rate = 5e-05
  task_learning_rate = 0.0005
  max_segment_len = 128
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/test.english.128.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}

train_spanbert_base = ${best}{
  num_docs = 2802
  bert_learning_rate = 2e-05
  task_learning_rate = 0.0001
  max_segment_len = 384
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.384.jsonlines
  eval_path = ${data_dir}/test.english.384.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}

qa = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 128
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/test.english.128.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}

train_spanbert_base_radam = ${best}{
  num_docs = 2802
  bert_learning_rate = 3e-05
  task_learning_rate = 1e-3
  max_segment_len = 128
  ffnn_size = 3000
  adam_eps = 1e-8
  num_epochs = 30
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/test.english.128.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
  task_optimizer = radam
}
train_bert_base = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 128
  ffnn_size = 1000
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/dev.english.128.jsonlines
  conll_eval_path = ${data_dir}/dev.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = ${best.log_root}/cased_L-12_H-768_A-12/bert_config.json
  vocab_file = ${best.log_root}/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = ${best.log_root}/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = ${best.log_root}/cased_L-12_H-768_A-12/bert_model.ckpt
}
train_spanbert_base_ratio3 = ${best}{
  num_docs = 2802
  bert_learning_rate = 2e-05
  task_learning_rate = 3e-4
  max_segment_len = 128
  ffnn_size = 3000
  top_span_ratio = 0.3
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/dev.english.128.jsonlines
  conll_eval_path = ${data_dir}/dev.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}
train_spanbert_base_ratio5 = ${best}{
  num_docs = 2802
  bert_learning_rate = 2e-05
  task_learning_rate = 3e-4
  max_segment_len = 128
  ffnn_size = 1000
  top_span_ratio = 0.5
  train_path = ${data_dir}/train.english.128.jsonlines
  eval_path = ${data_dir}/dev.english.128.jsonlines
  conll_eval_path = ${data_dir}/dev.english.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}
bert_large = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 384
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.384.jsonlines
  eval_path = ${data_dir}/dev.english.384.jsonlines
  conll_eval_path = ${data_dir}/dev.english.v4_gold_conll
  max_training_sentences = 3
  bert_config_file = ${best.log_root}/bert_large/bert_config.json
  vocab_file = ${best.log_root}/bert_large/vocab.txt
  tf_checkpoint = ${best.log_root}/bert_large/model.max.ckpt
  init_checkpoint = ${best.log_root}/bert_large/model.max.ckpt
}

train_bert_large = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 384
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.384.jsonlines
  eval_path = ${data_dir}/dev.english.384.jsonlines
  conll_eval_path = ${data_dir}/dev.english.v4_gold_conll
  max_training_sentences = 3
  bert_config_file = ${best.log_root}/cased_L-24_H-1024_A-16/bert_config.json
  vocab_file = ${best.log_root}/cased_L-24_H-1024_A-16/vocab.txt
  tf_checkpoint = ${best.log_root}/cased_L-24_H-1024_A-16/bert_model.ckpt
  init_checkpoint = ${best.log_root}/cased_L-24_H-1024_A-16/bert_model.ckpt
}

spanbert_base = ${best}{
  num_docs = 2802
  bert_learning_rate = 2e-05
  task_learning_rate = 0.0001
  max_segment_len = 384
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.384.jsonlines
  eval_path = ${data_dir}/test.english.384.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 3
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}

spanbert_base_256 = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-5
  task_learning_rate = 2e-4
  max_segment_len = 256
  ffnn_size = 1000
  train_path = ${data_dir}/train.english.256.jsonlines
  eval_path = ${data_dir}/test.english.256.jsonlines
  conll_eval_path = ${data_dir}/test.english.v4_gold_conll
  max_training_sentences = 5
  bert_config_file = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/config.json
  vocab_file = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = /data/nfsdata/nlp/BERT_BASE_DIR/spanbert_base/pytorch_model.bin
}

spanbert_large = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0003
  max_segment_len = 512
  ffnn_size = 3000
  train_path = ${data_dir}/train.english.512.jsonlines
  eval_path = ${data_dir}/dev.english.512.jsonlines
  conll_eval_path = ${data_dir}/dev.english.v4_gold_conll
  max_training_sentences = 3
  bert_config_file = ${best.log_root}/spanbert_large/bert_config.json
  vocab_file = ${best.log_root}/spanbert_large/vocab.txt
  tf_checkpoint = ${best.log_root}/spanbert_large/model.max.ckpt
  init_checkpoint = ${best.log_root}/spanbert_large/model.max.ckpt
}
